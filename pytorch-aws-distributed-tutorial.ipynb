{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch 1.0 Distributed Trainer with Amazon AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nathan Inkawhich, Pieter Noordhuis & Teng Li**\n",
    "\n",
    "In this tutorial we will show how to setup, code, and run a PyTorch 1.0 distributed trainer across two multi-gpu Amazon AWS nodes. We will start with describing the AWS setup, then the PyTorch environment configuration, and finally the code for the distributed trainer. Hopefully you will find that there is actually very little code change required to extend your current training code to a distributed application, and most of the work is in the one-time environment setup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon AWS Setup\n",
    "\n",
    "### Creating the Nodes\n",
    "\n",
    "- deeplearning AMI nodes\n",
    "- using p2.8xlarge here\n",
    "- create a new security group\n",
    "\n",
    "### Configure Security Group\n",
    "\n",
    "- configure settings in security group to allow all traffic between nodes in the security group\n",
    "- test that nodes can talk\n",
    "\n",
    "```\n",
    "Run on machine A: nc -l 12345\n",
    "Run on machine B: echo \"hello world\" | nc <IP of A> 1234\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "- new conda env with python 3.6 and numpy\n",
    "    - `conda create -n nightly_pt python=3.6 numpy`\n",
    "    - `source activate nightly_pt`\n",
    "- install pytorch\n",
    "    - `pip install torch_nightly -f https://download.pytorch.org/whl/nightly/cu90/torch_nightly.html`\n",
    "- install torchvision from source\n",
    "    - clone it to local machine: `git clone https://github.com/pytorch/vision.git`\n",
    "    - build it with: `python setup.py install`\n",
    "- Very Important: NCCL_SOCKET_IFNAME=ens3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed Training Code\n",
    "\n",
    "- Most of the code here has been taken from the [PyTorch ImageNet Example](https://github.com/pytorch/examples/tree/master/imagenet) which also supports distributed training. This code provides a good starting point for a custom trainer as it has much of the boilerplate training loop, validation loop, and accuracy tracking functionality. However, you will notice that the argument parsing and other non-essential functions have been stripped out for simplicity.\n",
    "\n",
    "- In this example we will use [torchvision.models.resnet18](https://pytorch.org/docs/stable/torchvision/models.html#torchvision.models.resnet18) model and will train it on the [torchvision.datasets.STL10](https://pytorch.org/docs/stable/torchvision/datasets.html#torchvision.datasets.STL10) dataset for simplicity. To accomodate for the dimensionality mismatch of STL-10 with Resnet18, we will resize each image to 224x224 with a transform. Notice, the choice of model and dataset are orthogonal to the distributed training code, you may use any dataset and model you wish and the process is the same. Lets get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "First let's get the imports out of the way. The important imports here are [torch.nn.parallel](https://pytorch.org/docs/stable/nn.html#torch.nn.parallel.DistributedDataParallel), [torch.distributed](https://pytorch.org/docs/stable/distributed.html), [torch.utils.data.distributed](https://pytorch.org/docs/stable/data.html#torch.utils.data.distributed.DistributedSampler), and [torch.multiprocessing](https://pytorch.org/docs/stable/multiprocessing.html). It is also important to set the multiprocessing start method to *spawn*, as the default is *fork* which may cause deadlocks when using multiple worker threads for dataloading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "from torch.multiprocessing import Pool, Process, set_start_method\n",
    "try:\n",
    "    set_start_method('spawn')\n",
    "except RuntimeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
